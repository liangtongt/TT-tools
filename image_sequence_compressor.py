import os
import json
import base64
import numpy as np
from PIL import Image
import io
import zlib
from typing import List, Dict, Any, Optional
import torch
import cv2
import tempfile

class TTImg:
    """TT img - å›¾ç‰‡åºåˆ—å‹ç¼©å™¨èŠ‚ç‚¹"""
    
    # èŠ‚ç‚¹ç‰ˆæœ¬å· - æ¯æ¬¡æ›´æ–°ä»£ç æ—¶é€’å¢
    VERSION = "1.0.1"
    BUILD_DATE = "2024-08-30"
    
    def __init__(self):
        self.compression_level = 6
        self.quality = 95
        self.format = "PNG"
        print(f"ğŸš€ TT img èŠ‚ç‚¹å·²åŠ è½½ - ç‰ˆæœ¬: {self.VERSION} ({self.BUILD_DATE})")
        
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),
                "quality": ("INT", {"default": 100, "min": 1, "max": 100}),
                "use_original_size": ("BOOLEAN", {"default": True})
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    FUNCTION = "compress_sequence"
    CATEGORY = "TT"
    OUTPUT_NODE = True  # å¯ç”¨èŠ‚ç‚¹é¢„è§ˆåŠŸèƒ½
    
    # èŠ‚ç‚¹å…ƒæ•°æ® - å‰ç«¯å¯ä»¥è¯»å–è¿™äº›ä¿¡æ¯
    @classmethod
    def IS_CHANGED(cls, **kwargs):
        """è¿”å›èŠ‚ç‚¹ç‰ˆæœ¬ä¿¡æ¯ï¼Œç”¨äºæ£€æµ‹èŠ‚ç‚¹æ˜¯å¦æ›´æ–°"""
        return f"TT_img_v{cls.VERSION}_{cls.BUILD_DATE}"
    
    def compress_sequence(self, images, quality, use_original_size):
        """å°†å›¾ç‰‡åºåˆ—å‹ç¼©å¹¶åµŒå…¥åˆ°è‡ªåŠ¨ç”Ÿæˆçš„æ‰¿è½½å›¾åƒä¸­"""
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadata = {
            "image_count": len(images),
            "quality": quality,
            "timestamp": str(np.datetime64('now')),
            "type": "single" if len(images) == 1 else "sequence"
        }
        
        # æ ¹æ®å›¾ç‰‡æ•°é‡é€‰æ‹©å¤„ç†æ–¹å¼
        if len(images) == 1:
            # å•å¼ å›¾ç‰‡ï¼šç¼–ç æˆJPEG
            compressed_data = self._compress_single_image(images[0], quality)
            metadata["type"] = "single"
            metadata["format"] = "JPEG"
        else:
            # å¤šå¼ å›¾ç‰‡ï¼šç¼–ç æˆMP4
            compressed_data = self._compress_image_sequence(images, quality)
            metadata["type"] = "sequence"
            metadata["format"] = "MP4"
        
        # å°†å‹ç¼©æ•°æ®ç¼–ç ä¸ºbase64
        base64_data = base64.b64encode(compressed_data).decode('utf-8')
        
        # åˆ›å»ºåŒ…å«æ‰€æœ‰æ•°æ®çš„å­—å…¸
        combined_data = {
            "metadata": metadata,
            "data": base64_data
        }
        
        # å°†æ•°æ®ç¼–ç ä¸ºJSONå­—ç¬¦ä¸²
        json_data = json.dumps(combined_data, indent=2)
        

        
        # ç¡®å®šæ‰¿è½½å›¾åƒå°ºå¯¸
        if use_original_size and len(images) > 0:
            # ä½¿ç”¨ç¬¬ä¸€å¼ å›¾ç‰‡çš„åŸå§‹å°ºå¯¸
            first_img = self._tensor_to_numpy(images[0])
            container_width, container_height = first_img.shape[1], first_img.shape[0]
        else:
            # ä½¿ç”¨é»˜è®¤å°ºå¯¸
            container_width, container_height = 512, 512
        
        # åˆ›å»ºæ‰¿è½½å›¾åƒ
        container_image = self._create_container_image(container_width, container_height)
        
        # å°†JSONæ•°æ®åµŒå…¥åˆ°å›¾åƒä¸­
        final_image = self._embed_data_in_image(container_image, json_data)
        
        # ç®€åŒ–å¹¶ä¿®å¤è¾“å‡ºæ ¼å¼å¤„ç†ï¼Œç¡®ä¿100%ç¬¦åˆComfyUIè¦æ±‚
        # å°†PILå›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
        final_array = np.array(final_image)
        
        # å¼ºåˆ¶è½¬æ¢ä¸º3é€šé“RGBæ ¼å¼
        if len(final_array.shape) == 3:
            if final_array.shape[2] == 3:  # HWCæ ¼å¼
                # è½¬æ¢ä¸ºCHWæ ¼å¼
                final_array = np.transpose(final_array, (2, 0, 1))
            elif final_array.shape[2] == 4:  # RGBAæ ¼å¼
                # è½¬æ¢ä¸ºRGBï¼Œç„¶åè½¬æ¢ä¸ºCHW
                final_array = final_array[:, :, :3]
                final_array = np.transpose(final_array, (2, 0, 1))
            elif final_array.shape[0] == 3:  # å·²ç»æ˜¯CHWæ ¼å¼
                pass
            else:
                # å…¶ä»–æƒ…å†µï¼Œå¼ºåˆ¶è½¬æ¢ä¸º3é€šé“
                final_array = np.stack([final_array[:, :, 0]] * 3, axis=0)
        else:
            # å¦‚æœä¸æ˜¯3Dï¼Œå¼ºåˆ¶è½¬æ¢ä¸º3é€šé“
            final_array = np.stack([final_array] * 3, axis=0)
        
        # ç¡®ä¿æ˜¯3é€šé“CHWæ ¼å¼
        if final_array.shape[0] != 3:
            if len(final_array.shape) == 3 and final_array.shape[2] == 3:
                final_array = np.transpose(final_array, (2, 0, 1))
            else:
                final_array = np.stack([final_array[:, :, 0]] * 3, axis=0)
        
        # è½¬æ¢ä¸ºfloat32å¹¶å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        final_array = final_array.astype(np.float32) / 255.0
        
        # ç¡®ä¿æ•°å€¼èŒƒå›´åœ¨0-1ä¹‹é—´
        final_array = np.clip(final_array, 0.0, 1.0)
        
        # è½¬æ¢ä¸ºTensor
        final_tensor = torch.from_numpy(final_array).float()
        
        # æ·»åŠ æ‰¹æ¬¡ç»´åº¦ (1, C, H, W)
        final_tensor = final_tensor.unsqueeze(0)
        
        # æœ€ç»ˆéªŒè¯å’Œå¼ºåˆ¶ä¿®æ­£è¾“å‡ºæ ¼å¼
        expected_shape = (1, 3, final_array.shape[1], final_array.shape[2])
        if final_tensor.shape != expected_shape:
            print(f"è­¦å‘Šï¼šè¾“å‡ºå½¢çŠ¶ä¸æ­£ç¡®: {final_tensor.shape}ï¼Œå¼ºåˆ¶ä¿®æ­£ä¸º: {expected_shape}")
            try:
                final_tensor = final_tensor.view(expected_shape)
            except:
                # å¦‚æœviewå¤±è´¥ï¼Œé‡æ–°åˆ›å»ºtensor
                final_tensor = torch.zeros(expected_shape, dtype=torch.float32)
                # å¤åˆ¶æ•°æ®
                min_h = min(final_tensor.shape[2], final_array.shape[1])
                min_w = min(final_tensor.shape[3], final_array.shape[2])
                final_tensor[0, :, :min_h, :min_w] = torch.from_numpy(final_array[:, :min_h, :min_w])
        
        # ç”Ÿæˆé¢„è§ˆå›¾åƒï¼ˆç¼©ç•¥å›¾ï¼‰
        preview_image = self._create_preview_image(final_image)
        
        # è¾“å‡ºç‰ˆæœ¬ä¿¡æ¯åˆ°æ§åˆ¶å°
        print(f"âœ… TT img èŠ‚ç‚¹å¤„ç†å®Œæˆ - ç‰ˆæœ¬: {self.VERSION}")
        print(f"  è¾“å…¥å›¾åƒæ•°é‡: {len(images)}")
        print(f"  è¾“å‡ºå›¾åƒå°ºå¯¸: {final_tensor.shape}")
        print(f"  å‹ç¼©è´¨é‡: {quality}")
        print(f"  ä½¿ç”¨åŸå§‹å°ºå¯¸: {use_original_size}")
        
        return (final_tensor,)
    
    def _embed_data_in_image(self, image, data):
        """å°†æ•°æ®åµŒå…¥åˆ°å›¾åƒä¸­ï¼ˆæœ€å°åŒ–åƒç´ ä¿®æ”¹ï¼‰"""
        # å°†æ•°æ®è½¬æ¢ä¸ºåƒç´ å€¼
        data_bytes = data.encode('utf-8')
        data_length = len(data_bytes)
        
        # åˆ›å»ºå›¾åƒå‰¯æœ¬
        new_image = image.copy()
        width, height = new_image.size
        
        # æ£€æŸ¥å›¾åƒæ˜¯å¦æœ‰è¶³å¤Ÿçš„åƒç´ æ¥å­˜å‚¨æ•°æ®
        total_pixels = width * height
        required_pixels = data_length + 4  # +4 for length info
        
        if total_pixels < required_pixels:
            # å¦‚æœå›¾åƒå¤ªå°ï¼Œæ‰©å±•å›¾åƒï¼Œä½†é™åˆ¶æœ€å¤§å°ºå¯¸
            required_pixels = data_length + 4  # +4 for length info
            
            # è®¡ç®—åˆç†çš„å›¾åƒå°ºå¯¸ï¼Œé™åˆ¶æœ€å¤§å°ºå¯¸ä¸º2048x2048
            max_dimension = 2048
            new_width = min(max(width, int(required_pixels ** 0.5) + 1), max_dimension)
            new_height = min(max(height, (required_pixels + new_width - 1) // new_width), max_dimension)
            
            # å¦‚æœä»ç„¶ä¸å¤Ÿï¼Œä½¿ç”¨æ›´ç´§å‡‘çš„å¸ƒå±€
            if new_width * new_height < required_pixels:
                new_width = min(int(required_pixels ** 0.5) + 1, max_dimension)
                new_height = min((required_pixels + new_width - 1) // new_width, max_dimension)
            
            # è°ƒè¯•ä¿¡æ¯å·²ç§»é™¤ï¼Œä¿æŒä»£ç æ¸…æ´
            
            new_image = Image.new('RGB', (new_width, new_height), (255, 255, 255))
            new_image.paste(image, (0, 0))
            width, height = new_image.size
        
        # å°†æ•°æ®é•¿åº¦åµŒå…¥åˆ°å‰4ä¸ªåƒç´ ä¸­ï¼ˆåªä¿®æ”¹çº¢è‰²é€šé“ï¼‰
        length_bytes = data_length.to_bytes(4, byteorder='big')
        for i in range(4):
            x, y = i % width, i // width
            if y < height:
                original_pixel = new_image.getpixel((x, y))
                new_image.putpixel((x, y), (length_bytes[i], original_pixel[1], original_pixel[2]))
        
        # å°†æ•°æ®åµŒå…¥åˆ°åç»­åƒç´ ä¸­ï¼ˆåªä¿®æ”¹çº¢è‰²é€šé“ï¼‰
        for i, byte_val in enumerate(data_bytes):
            pixel_index = i + 4  # è·³è¿‡é•¿åº¦ä¿¡æ¯
            x, y = pixel_index % width, pixel_index // width
            if y < height:
                original_pixel = new_image.getpixel((x, y))
                new_image.putpixel((x, y), (byte_val, original_pixel[1], original_pixel[2]))
        
        return new_image
    
    def _compress_single_image(self, img_array, quality):
        """å‹ç¼©å•å¼ å›¾ç‰‡ä¸ºJPEGæ ¼å¼"""
        # å¤„ç†Tensorå¯¹è±¡ï¼Œè½¬æ¢ä¸ºnumpyæ•°ç»„
        if torch.is_tensor(img_array):
            img_array = img_array.cpu().numpy()
            # å¤„ç†æ‰¹æ¬¡ç»´åº¦
            if len(img_array.shape) == 4:
                img_array = img_array[0]
            # Tensoré€šå¸¸æ˜¯CHWæ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸ºHWCæ ¼å¼
            if len(img_array.shape) == 3 and img_array.shape[0] == 3:
                img_array = np.transpose(img_array, (1, 2, 0))
        else:
            # å¤„ç†numpyæ•°ç»„çš„æ‰¹æ¬¡ç»´åº¦
            if len(img_array.shape) == 4:
                img_array = img_array[0]
        
        # è½¬æ¢numpyæ•°ç»„ä¸ºPILå›¾åƒ
        if img_array.dtype != np.uint8:
            img_array = (img_array * 255).astype(np.uint8)
        
        # ç¡®ä¿å›¾åƒæ˜¯3é€šé“RGB
        if len(img_array.shape) == 3 and img_array.shape[2] == 3:
            pil_img = Image.fromarray(img_array, 'RGB')
        elif len(img_array.shape) == 3 and img_array.shape[2] == 4:
            pil_img = Image.fromarray(img_array, 'RGBA')
            pil_img = pil_img.convert('RGB')
        else:
            pil_img = Image.fromarray(img_array, 'RGB')
        
        # å‹ç¼©ä¸ºJPEG
        img_buffer = io.BytesIO()
        pil_img.save(img_buffer, format="JPEG", quality=quality, optimize=True)
        return img_buffer.getvalue()
    
    def _compress_image_sequence(self, images, quality):
        """å‹ç¼©å›¾ç‰‡åºåˆ—ä¸ºMP4æ ¼å¼"""
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_file:
            temp_path = temp_file.name
        
        try:
            # è·å–ç¬¬ä¸€å¼ å›¾ç‰‡çš„å°ºå¯¸
            first_img = self._tensor_to_numpy(images[0])
            height, width = first_img.shape[:2]
            
            # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(temp_path, fourcc, 30.0, (width, height))
            
            # å†™å…¥æ¯ä¸€å¸§
            for img_array in images:
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                img_np = self._tensor_to_numpy(img_array)
                
                # ç¡®ä¿æ˜¯BGRæ ¼å¼ï¼ˆOpenCVéœ€è¦ï¼‰
                if len(img_np.shape) == 3 and img_np.shape[2] == 3:
                    img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
                else:
                    img_bgr = img_np
                
                out.write(img_bgr)
            
            out.release()
            
            # è¯»å–å‹ç¼©åçš„MP4æ–‡ä»¶
            with open(temp_path, 'rb') as f:
                mp4_data = f.read()
            
            return mp4_data
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                os.unlink(temp_path)
    
    def _tensor_to_numpy(self, img_array):
        """å°†Tensoræˆ–numpyæ•°ç»„è½¬æ¢ä¸ºæ ‡å‡†numpyæ•°ç»„"""
        # å¤„ç†Tensorå¯¹è±¡ï¼Œè½¬æ¢ä¸ºnumpyæ•°ç»„
        if torch.is_tensor(img_array):
            img_array = img_array.cpu().numpy()
            # å¤„ç†æ‰¹æ¬¡ç»´åº¦
            if len(img_array.shape) == 4:
                img_array = img_array[0]
            # Tensoré€šå¸¸æ˜¯CHWæ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸ºHWCæ ¼å¼
            if len(img_array.shape) == 3 and img_array.shape[0] == 3:
                img_array = np.transpose(img_array, (1, 2, 0))
        else:
            # å¤„ç†numpyæ•°ç»„çš„æ‰¹æ¬¡ç»´åº¦
            if len(img_array.shape) == 4:
                img_array = img_array[0]
        
        # è½¬æ¢æ•°å€¼èŒƒå›´
        if img_array.dtype != np.uint8:
            img_array = (img_array * 255).astype(np.uint8)
        
        return img_array
    
    def _create_container_image(self, width, height):
        """åˆ›å»ºæ‰¿è½½æ•°æ®çš„å›¾åƒï¼ˆé«˜è´¨é‡ï¼‰"""
        # åˆ›å»ºä¸€ä¸ªé«˜è´¨é‡çš„èƒŒæ™¯å›¾åƒ
        img = Image.new('RGB', (width, height), (255, 255, 255))
        
        # æ·»åŠ ä¸€äº›é«˜è´¨é‡çš„å›¾æ¡ˆï¼Œè®©å›¾åƒçœ‹èµ·æ¥æ›´è‡ªç„¶
        from PIL import ImageDraw
        
        draw = ImageDraw.Draw(img)
        
        # åˆ›å»ºæ¸å˜èƒŒæ™¯
        for y in range(height):
            # ä»ç™½è‰²åˆ°æµ…ç°è‰²çš„æ¸å˜
            intensity = int(255 - (y / height) * 20)
            color = (intensity, intensity, intensity)
            draw.line([(0, y), (width, y)], fill=color)
        
        # æ·»åŠ ä¸€äº›é«˜è´¨é‡çš„ç‚¹
        import random
        random.seed(42)  # å›ºå®šç§å­ï¼Œç¡®ä¿æ¯æ¬¡ç”Ÿæˆç›¸åŒçš„å›¾åƒ
        
        for _ in range(min(100, width * height // 100)):  # æ ¹æ®å›¾åƒå¤§å°è°ƒæ•´ç‚¹æ•°
            x = random.randint(0, width-1)
            y = random.randint(0, height-1)
            # ä½¿ç”¨æ›´è‡ªç„¶çš„é¢œè‰²
            color = (random.randint(240, 255), random.randint(240, 255), random.randint(240, 255))
            draw.point((x, y), fill=color)
        
        return img
    
    def _create_preview_image(self, image):
        """åˆ›å»ºé¢„è§ˆå›¾åƒï¼ˆç¼©ç•¥å›¾ï¼‰"""
        try:
            # åˆ›å»ºç¼©ç•¥å›¾
            preview_size = (256, 256)  # é¢„è§ˆå°ºå¯¸
            preview_image = image.copy()
            preview_image.thumbnail(preview_size, Image.Resampling.LANCZOS)
            
            # æ·»åŠ è¾¹æ¡†å’Œæ ‡é¢˜
            from PIL import ImageDraw, ImageFont
            
            # åˆ›å»ºå¸¦è¾¹æ¡†çš„å›¾åƒ
            border_size = 2
            bordered_size = (preview_image.width + border_size * 2, 
                           preview_image.height + border_size * 2 + 30)  # é¢å¤–30åƒç´ ç”¨äºæ ‡é¢˜
            bordered_image = Image.new('RGB', bordered_size, (200, 200, 200))
            
            # ç²˜è´´é¢„è§ˆå›¾åƒ
            bordered_image.paste(preview_image, (border_size, border_size))
            
            # æ·»åŠ æ ‡é¢˜
            draw = ImageDraw.Draw(bordered_image)
            try:
                # å°è¯•ä½¿ç”¨ç³»ç»Ÿå­—ä½“
                font = ImageFont.truetype("arial.ttf", 12)
            except:
                # ä½¿ç”¨é»˜è®¤å­—ä½“
                font = ImageFont.load_default()
            
            title = "TT img Preview"
            title_bbox = draw.textbbox((0, 0), title, font=font)
            title_width = title_bbox[2] - title_bbox[0]
            title_x = (bordered_image.width - title_width) // 2
            title_y = preview_image.height + border_size + 5
            
            # ç»˜åˆ¶æ ‡é¢˜èƒŒæ™¯
            draw.rectangle([title_x - 5, title_y - 2, 
                           title_x + title_width + 5, title_y + 15], 
                          fill=(100, 100, 100))
            
            # ç»˜åˆ¶æ ‡é¢˜æ–‡å­—
            draw.text((title_x, title_y), title, fill=(255, 255, 255), font=font)
            
            return bordered_image
            
        except Exception as e:
            print(f"é¢„è§ˆå›¾åƒåˆ›å»ºå¤±è´¥: {e}")
            # å¦‚æœé¢„è§ˆåˆ›å»ºå¤±è´¥ï¼Œè¿”å›åŸå›¾åƒ
            return image

# èŠ‚ç‚¹æ³¨å†Œå·²ç§»è‡³ __init__.py
